{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read Senseval's and Semeval's test data\n",
    "# 2. Read Sense Inventory with Glosses\n",
    "# 3. Convert the test data and glosses into prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Sequence, Dict, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "\n",
    "datadir = Path(\"../data/en/\")\n",
    "\n",
    "\n",
    "def read_keys(filepath: str) -> Dict[str, str]:\n",
    "    keys = {}\n",
    "    with open(filepath, 'r') as ifile:\n",
    "        for line in ifile:\n",
    "            row = line.strip().split()\n",
    "            keys[row[0]] = row[1:]\n",
    "    return keys\n",
    "\n",
    "def read_data(filepath: str) -> Sequence[Tuple[str, Any]]:\n",
    "    data = parse(filepath)\n",
    "\n",
    "    for text in data.getElementsByTagName('text'):\n",
    "        source = text.getAttribute('source')\n",
    "        id = text.getAttribute('id')\n",
    "        yield (source, id, text)\n",
    "\n",
    "def read_directory(datadir: Path) -> Sequence[Any]:\n",
    "    data = {}\n",
    "\n",
    "    keys = {\n",
    "        '.data.xml': 'data',\n",
    "        '.gold.key.txt': 'bn-keys',\n",
    "        '.gold.key.txt.pwn': 'wn-keys'\n",
    "    }\n",
    "\n",
    "    for filepath in datadir.iterdir():\n",
    "        key = ''.join(filepath.suffixes)\n",
    "        if key not in keys:\n",
    "            continue\n",
    "\n",
    "        if key.endswith('.xml'):\n",
    "            data[keys[key]] = list(read_data(str(filepath)))\n",
    "        else:\n",
    "            data[keys[key]] = read_keys(str(filepath))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "\n",
    "    def __init__(self, elem):\n",
    "        self._elem = elem\n",
    "\n",
    "    @property\n",
    "    def pos(self):\n",
    "        return self._elem.getAttribute('pos')\n",
    "\n",
    "    @property\n",
    "    def lemma(self):\n",
    "        try:\n",
    "            return self._elem.getAttribute('lemma')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    @property\n",
    "    def orth(self):\n",
    "        return self._elem.firstChild.nodeValue\n",
    "\n",
    "    @property\n",
    "    def instance(self):\n",
    "        try:\n",
    "            return self._elem.getAttribute('id')\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import Element\n",
    "\n",
    "def parse_sentence(sentence: Element) -> List[str]:\n",
    "    text = []\n",
    "\n",
    "    for elem in sentence.childNodes:\n",
    "        token = Token(elem)\n",
    "        try:\n",
    "            if token.pos == 'PUNCT':\n",
    "                text.append(f\"{token.orth} \") \n",
    "            else:\n",
    "                text.append(f\" {token.orth}\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return ''.join(text).replace('  ', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import Element\n",
    "\n",
    "\n",
    "class Inventory:\n",
    "\n",
    "    def __init__(self, datapath: Path):\n",
    "        data = self._read_data(datapath)\n",
    "        self._pos_mapping = {\n",
    "            '1': 'NOUN',\n",
    "            '2': 'VERB',\n",
    "            '3': 'ADJ',\n",
    "            '4': 'ADV',\n",
    "            '5': 'ADJ'\n",
    "        }\n",
    "        self._lemma_index = self._create_lemma_index(data)\n",
    "        self._sense_index = self._create_sense_index(data)\n",
    "\n",
    "    def _read_data(self, datapath: Path) -> Sequence[Any]:\n",
    "        pass\n",
    "\n",
    "    def _create_lemma_index(self, data: Any) -> Dict[str, List[str]]:\n",
    "        pass\n",
    "\n",
    "    def _create_sense_index(self, data: Any) -> Dict[str, List[str]]:\n",
    "        pass\n",
    "\n",
    "    def sense_glosses(self, key: str) -> List[str]:\n",
    "        return self._sense_index[key]\n",
    "\n",
    "    def lemma_glosses(self, lemma: str, pos: str, ret_key: bool = False) -> List[str]:\n",
    "        if ret_key:\n",
    "            return [(key, self._sense_index[key])\n",
    "                    for key in self._lemma_index[(lemma, pos)]]\n",
    "                    \n",
    "        return [self._sense_index[key] for key in self._lemma_index[(lemma, pos)]]\n",
    "\n",
    "\n",
    "class XMLInventory(Inventory):\n",
    "\n",
    "    def __init__(self, datadir: Path):\n",
    "        super(XMLInventory, self).__init__(datadir)\n",
    "    \n",
    "    def _read_data(self, datapath: Path) -> Sequence[Any]:\n",
    "        return read_directory(datapath)\n",
    "\n",
    "    def _create_lemma_index(self, inventory: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "        index = {}\n",
    "\n",
    "        for source, _, text in tqdm(inventory['data']):\n",
    "            sense_key = source\n",
    "            \n",
    "            lemma, attrs = source.split('%')\n",
    "            pos = self._pos_mapping[attrs.split(':')[0]]\n",
    "\n",
    "            if (lemma, pos) not in index:\n",
    "                index[(lemma, pos)] = []\n",
    "            index[(lemma, pos)].append(sense_key)\n",
    "            \n",
    "        return index\n",
    "    \n",
    "    def _create_sense_index(self, inventory: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "        index = {}\n",
    "\n",
    "        for source, _, text in tqdm(inventory['data']):\n",
    "            sense_key = source\n",
    "\n",
    "            glosses = [\n",
    "                parse_sentence(sentence)\n",
    "                for sentence in text.getElementsByTagName('sentence')\n",
    "            ]\n",
    "            index[sense_key] = glosses\n",
    "            \n",
    "        return index\n",
    "\n",
    "\n",
    "class PlainInventory(Inventory):\n",
    "\n",
    "    def __init__(self, datapath: Path):\n",
    "        super(PlainInventory, self).__init__(datapath)\n",
    "\n",
    "    def _read_data(self, datapath: Path) -> Sequence[List[str]]:\n",
    "        data = []\n",
    "        with open(str(datapath), 'r') as ifile:\n",
    "            for line in ifile:\n",
    "                row = line.strip().split('\\t')\n",
    "                data.append(row)\n",
    "        return data\n",
    "\n",
    "    def _create_lemma_index(self, data: Any) -> Dict[str, List[str]]:\n",
    "        index = {}\n",
    "        for row in tqdm(data):\n",
    "            sense_key = row[0]\n",
    "\n",
    "            lemma, attrs = sense_key.split('%')\n",
    "            pos = self._pos_mapping[attrs.split(':')[0]]\n",
    "\n",
    "            if (lemma, pos) not in index:\n",
    "                index[(lemma, pos)] = []\n",
    "            index[(lemma, pos)].append(sense_key)\n",
    "        \n",
    "        return index\n",
    "\n",
    "    def _create_sense_index(self, data: Any) -> Dict[str, List[str]]:\n",
    "        index = {}\n",
    "        for row in tqdm(data):\n",
    "            sense_key, gloss = row[0], row[-1]\n",
    "            lemma = sense_key.split('%')[0]\n",
    "\n",
    "            # index[sense_key] = f\"{lemma}: {gloss}\"\n",
    "            index[sense_key] = gloss\n",
    "\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory = XMLInventory(datadir / \"inventory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory.lemma_glosses('evoke', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206941/206941 [00:00<00:00, 880307.45it/s]\n",
      "100%|██████████| 206941/206941 [00:00<00:00, 2154101.02it/s]\n"
     ]
    }
   ],
   "source": [
    "inventory = PlainInventory(datadir / \"inventory/wngt_glosses.plain.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('evoke%2:32:01::', 'call to mind'),\n",
       " ('evoke%2:36:00::', 'evoke or provoke to appear or occur'),\n",
       " ('evoke%2:36:01::', 'deduce (a principle) or construe (a meaning)'),\n",
       " ('evoke%2:36:02::',\n",
       "  'summon into action or bring into existence, often as if by magic'),\n",
       " ('evoke%2:37:00::', 'call forth (emotions, feelings, and responses)')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory.lemma_glosses('evoke', 'VERB', ret_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdata = read_directory(datadir / \"test\")\n",
    "testdata = read_directory(datadir / \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "class TokenWindowContext:\n",
    "\n",
    "    def __init__(self, wsize: int = 30) -> None:\n",
    "        self._wsize = wsize\n",
    "\n",
    "    def _sense_annotated(self, token: Token) -> bool:\n",
    "        return token.is_instance\n",
    "\n",
    "    def __call__(self, sequence: Sequence[Element]) -> Sequence[Sequence[Element]]:\n",
    "        for ind, token in enumerate(sequence):\n",
    "            if self._sense_annotated(token):\n",
    "                yield sequence[:ind][-self._wsize:] + sequence[ind:][:self._wsize]\n",
    "\n",
    "\n",
    "class SentenceWindowContext:\n",
    "\n",
    "    def __init__(self, wsize: int = 2) -> None:\n",
    "        self._wsize = wsize\n",
    "\n",
    "    def __call__(self, sequence: Sequence[Element]) -> Sequence[Sequence[Element]]:\n",
    "        for ind, _ in enumerate(sequence):\n",
    "            for token in sequence[ind].childNodes:\n",
    "                token = Token(token)\n",
    "                if not token.instance:\n",
    "                    continue\n",
    "\n",
    "                lbound = min(self._wsize, len(sequence[:ind]))\n",
    "                rbound = 2 * self._wsize - lbound + 1\n",
    "\n",
    "                yield (token.lemma, token.pos, token.instance), list(chain(*[\n",
    "                        sequence[:ind][-lbound:],\n",
    "                        sequence[ind:][:rbound]\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "contexter = SentenceWindowContext(wsize=2)\n",
    "\n",
    "texts = list(chain(*[text.getElementsByTagName('sentence')\n",
    "                     for _, _, text in testdata['data']]))\n",
    "\n",
    "contexts = contexter(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read gold data\n",
    "gold = {}\n",
    "# with open(datadir / \"test/ALL.gold.key.txt\") as ifile:\n",
    "with open(datadir / \"valid/semeval2007.gold.key.txt\") as ifile:\n",
    "    for line in ifile:\n",
    "        row = line.strip().split()\n",
    "        key, val = row[0], row[1]\n",
    "        gold[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn-keys': {'d000.s000.t000': ['refer%2:32:01::'],\n",
       "  'd000.s000.t001': ['research%1:04:00::'],\n",
       "  'd000.s000.t002': ['report%2:32:04::'],\n",
       "  'd000.s001.t000': ['comment%1:10:00::'],\n",
       "  'd000.s001.t001': ['imply%2:32:00::'],\n",
       "  'd000.s001.t002': ['discover%2:31:01::'],\n",
       "  'd000.s001.t003': ['cause%1:11:00::'],\n",
       "  'd000.s001.t004': ['find%2:39:02::'],\n",
       "  'd000.s002.t000': ['make%2:36:12::'],\n",
       "  'd000.s002.t001': ['statement%1:10:06::'],\n",
       "  'd000.s003.t000': ['become%2:30:00::'],\n",
       "  'd000.s004.t000': ['cause%1:11:00::'],\n",
       "  'd000.s004.t001': ['understand%2:31:00::'],\n",
       "  'd000.s005.t000': ['quote%2:32:02::'],\n",
       "  'd000.s005.t001': ['emphasize%2:32:00::'],\n",
       "  'd000.s006.t000': ['note%2:32:00::'],\n",
       "  'd000.s006.t001': ['people%1:14:00::'],\n",
       "  'd000.s006.t002': ['examine%2:39:00::'],\n",
       "  'd000.s006.t003': ['have%2:29:02::'],\n",
       "  'd000.s006.t004': ['multitude%1:23:00::'],\n",
       "  'd000.s007.t000': ['suffer%2:29:01::', 'suffer%2:29:03::'],\n",
       "  'd000.s008.t000': ['people%1:14:00::'],\n",
       "  'd000.s008.t001': ['lack%2:42:00::'],\n",
       "  'd000.s008.t002': ['shelter%1:26:00::'],\n",
       "  'd000.s008.t003': ['lack%2:42:00::'],\n",
       "  'd000.s008.t004': ['necessity%1:17:00::'],\n",
       "  'd000.s009.t000': ['point_out%2:32:01::'],\n",
       "  'd000.s009.t001': ['problem%1:26:00::'],\n",
       "  'd000.s009.t002': ['predispose%2:31:00::'],\n",
       "  'd000.s009.t003': ['person%1:03:00::'],\n",
       "  'd000.s009.t004': ['category%1:14:00::'],\n",
       "  'd000.s009.t005': ['compose%2:42:00::'],\n",
       "  'd000.s009.t006': ['lack%2:42:00::'],\n",
       "  'd000.s009.t007': ['shelter%1:26:00::'],\n",
       "  'd000.s010.t000': ['interaction%1:04:00::'],\n",
       "  'd000.s010.t001': ['defy%2:42:01::'],\n",
       "  'd000.s010.t002': ['generalization%1:09:00::'],\n",
       "  'd000.s011.t000': ['look_to%2:31:01::'],\n",
       "  'd000.s011.t001': ['prevent%2:41:01::'],\n",
       "  'd000.s012.t000': ['require%2:42:00::'],\n",
       "  'd000.s012.t001': ['develop%2:30:06::'],\n",
       "  'd000.s012.t002': ['understanding%1:09:01::'],\n",
       "  'd000.s012.t003': ['possess%2:42:00::'],\n",
       "  'd000.s012.t004': ['develop%2:30:06::'],\n",
       "  'd000.s014.t000': ['study%1:10:00::'],\n",
       "  'd000.s014.t001': ['say%2:32:01::'],\n",
       "  'd000.s015.t000': ['study%1:10:00::'],\n",
       "  'd000.s015.t001': ['show%2:31:00::'],\n",
       "  'd000.s015.t002': ['make_up%2:42:00::'],\n",
       "  'd000.s015.t003': ['exhibit%2:42:00::'],\n",
       "  'd000.s015.t004': ['combination%1:14:00::'],\n",
       "  'd000.s016.t000': ['problem%1:26:00::'],\n",
       "  'd000.s016.t001': ['create%2:36:00::'],\n",
       "  'd000.s016.t002': ['result%2:42:02::'],\n",
       "  'd000.s016.t003': ['connect%2:31:00::'],\n",
       "  'd000.s016.t004': ['person%1:03:00::'],\n",
       "  'd000.s016.t005': ['live%2:42:06::'],\n",
       "  'd000.s018.t000': ['quote%2:32:00::'],\n",
       "  'd000.s018.t001': ['director%1:18:00::'],\n",
       "  'd000.s018.t002': ['center%1:06:00::'],\n",
       "  'd000.s018.t003': ['sleep%2:29:00::'],\n",
       "  'd000.s018.t004': ['rob%2:40:00::'],\n",
       "  'd000.s019.t000': ['fend%2:41:00::'],\n",
       "  'd000.s020.t000': ['have%2:29:02::'],\n",
       "  'd000.s020.t001': ['addiction%1:26:00::'],\n",
       "  'd000.s021.t000': ['fall%2:38:03::'],\n",
       "  'd000.s024.t000': ['dismiss%2:32:00::'],\n",
       "  'd000.s024.t001': ['view%1:09:02::'],\n",
       "  'd000.s024.t002': ['reduction%1:04:00::'],\n",
       "  'd000.s024.t003': ['play%2:41:12::'],\n",
       "  'd000.s024.t004': ['role%1:04:00::'],\n",
       "  'd000.s024.t005': ['number%1:07:00::'],\n",
       "  'd000.s024.t006': ['woman%1:18:00::'],\n",
       "  'd000.s025.t000': ['bother%2:41:00::'],\n",
       "  'd000.s025.t001': ['consider%2:39:00::'],\n",
       "  'd000.s026.t000': ['research%1:04:00::'],\n",
       "  'd000.s026.t001': ['stop%2:42:13::'],\n",
       "  'd000.s026.t002': ['assertion%1:10:01::'],\n",
       "  'd000.s026.t003': ['make%2:36:12::'],\n",
       "  'd000.s028.t000': ['march%1:14:00::'],\n",
       "  'd000.s028.t001': ['choose%2:31:01::'],\n",
       "  'd000.s028.t002': ['cite%2:32:00::'],\n",
       "  'd000.s028.t003': ['group%1:03:00::'],\n",
       "  'd000.s028.t004': ['insinuate%2:32:00::'],\n",
       "  'd000.s028.t005': ['get%2:40:00::'],\n",
       "  'd000.s028.t006': ['support%1:21:01::'],\n",
       "  'd000.s028.t007': ['know%2:31:12::'],\n",
       "  'd000.s028.t008': ['thing%1:09:02::'],\n",
       "  'd000.s028.t009': ['see%2:39:02::'],\n",
       "  'd000.s028.t010': ['crusade%1:04:00::'],\n",
       "  'd000.s028.t011': ['base%2:31:00::'],\n",
       "  'd000.s029.t000': ['force%1:07:01::'],\n",
       "  'd000.s029.t001': ['subscribe%2:40:00::'],\n",
       "  'd000.s029.t002': ['advertise%2:32:00::'],\n",
       "  'd000.s030.t000': ['mention%2:32:02::'],\n",
       "  'd000.s030.t001': ['organization%1:14:00::'],\n",
       "  'd000.s030.t002': ['participate%2:41:00::'],\n",
       "  'd000.s031.t000': ['homeless%1:18:00::'],\n",
       "  'd000.s031.t001': ['undergo%2:39:04::'],\n",
       "  'd000.s031.t002': ['examination%1:04:00::'],\n",
       "  'd000.s031.t003': ['suggest%2:32:00::'],\n",
       "  'd000.s031.t004': ['conduct%2:41:00::'],\n",
       "  'd000.s031.t005': ['survey%1:04:02::'],\n",
       "  'd000.s032.t000': ['choose%2:31:00::'],\n",
       "  'd000.s032.t001': ['executive%1:18:00::'],\n",
       "  'd000.s032.t002': ['include%2:42:00::'],\n",
       "  'd000.s032.t003': ['put%2:35:00::'],\n",
       "  'd000.s032.t004': ['deprive%2:40:00::'],\n",
       "  'd000.s033.t000': ['predict%2:32:00::'],\n",
       "  'd000.s033.t001': ['find%2:31:10::'],\n",
       "  'd000.s033.t002': ['increase%2:30:00::'],\n",
       "  'd001.s000.t000': ['account%1:10:00::'],\n",
       "  'd001.s000.t001': ['begin%2:42:03::'],\n",
       "  'd001.s001.t000': ['give%2:40:07::'],\n",
       "  'd001.s001.t001': ['example%1:09:00::'],\n",
       "  'd001.s002.t000': ['offer%2:40:00::'],\n",
       "  'd001.s002.t001': ['trip%1:04:00::'],\n",
       "  'd001.s002.t002': ['tell%2:32:01::'],\n",
       "  'd001.s002.t003': ['reader%1:18:03::'],\n",
       "  'd001.s002.t004': ['accept%2:40:00::'],\n",
       "  'd001.s002.t005': ['write_about%2:36:00::'],\n",
       "  'd001.s002.t006': ['decline%2:40:00::'],\n",
       "  'd001.s003.t000': ['question%1:10:00::'],\n",
       "  'd001.s003.t001': ['author%1:18:00::'],\n",
       "  'd001.s003.t002': ['believe%2:31:04::'],\n",
       "  'd001.s003.t003': ['answer%2:31:03::'],\n",
       "  'd001.s003.t004': ['read%2:31:00::'],\n",
       "  'd001.s003.t005': ['book%1:10:00::'],\n",
       "  'd001.s004.t000': ['lead%2:38:01::'],\n",
       "  'd001.s004.t001': ['path%1:04:00::'],\n",
       "  'd001.s004.t002': ['travel%2:38:02::'],\n",
       "  'd001.s004.t003': ['company%1:14:01::'],\n",
       "  'd001.s004.t004': ['contractor%1:18:00::'],\n",
       "  'd001.s004.t005': ['entrust%2:40:00::'],\n",
       "  'd001.s004.t006': ['produce%2:36:00::'],\n",
       "  'd001.s005.t000': ['book%1:10:00::'],\n",
       "  'd001.s005.t001': ['revolve_around%2:42:00::'],\n",
       "  'd001.s005.t002': ['become%2:42:01::'],\n",
       "  'd001.s005.t003': ['partner%1:18:00::'],\n",
       "  'd001.s006.t000': ['start%2:36:00::'],\n",
       "  'd001.s006.t001': ['get%2:30:12::'],\n",
       "  'd001.s006.t002': ['roll%2:35:01::'],\n",
       "  'd001.s006.t003': ['discover%2:40:00::'],\n",
       "  'd001.s006.t004': ['programme%1:09:01::'],\n",
       "  'd001.s007.t000': ['creation%1:06:00::'],\n",
       "  'd001.s007.t001': ['mandate%2:32:02::'],\n",
       "  'd001.s007.t002': ['contract%1:10:00::'],\n",
       "  'd001.s007.t003': ['award%2:40:01::'],\n",
       "  'd001.s008.t000': ['realize%2:31:01::'],\n",
       "  'd001.s008.t001': ['qualify%2:42:00::'],\n",
       "  'd001.s009.t000': ['partner%1:18:00::'],\n",
       "  'd001.s009.t001': ['have%2:32:00::'],\n",
       "  'd001.s009.t002': ['falsify%2:41:00::'],\n",
       "  'd001.s009.t003': ['ownership%1:21:00::'],\n",
       "  'd001.s010.t000': ['become%2:42:01::'],\n",
       "  'd001.s011.t000': ['locate%2:40:01::'],\n",
       "  'd001.s011.t001': ['area%1:15:01::'],\n",
       "  'd001.s011.t002': ['make%2:30:00::'],\n",
       "  'd001.s012.t000': ['company%1:14:01::'],\n",
       "  'd001.s012.t001': ['rebuild%2:36:00::'],\n",
       "  'd001.s012.t002': ['keep%2:42:07::'],\n",
       "  'd001.s012.t003': ['use%2:41:14::'],\n",
       "  'd001.s012.t004': ['angle%1:09:00::'],\n",
       "  'd001.s013.t000': ['start%2:30:00::'],\n",
       "  'd001.s013.t001': ['serve%2:42:00::'],\n",
       "  'd001.s013.t002': ['sentence%1:28:00::'],\n",
       "  'd001.s013.t003': ['company%1:14:01::'],\n",
       "  'd001.s013.t004': ['begin%2:30:01::'],\n",
       "  'd001.s013.t005': ['career%1:04:01::'],\n",
       "  'd001.s013.t006': ['bribe%2:40:00::'],\n",
       "  'd001.s013.t007': ['official%1:18:01::'],\n",
       "  'd001.s013.t008': ['include%2:42:00::'],\n",
       "  'd001.s014.t000': ['use%2:34:01::'],\n",
       "  'd001.s015.t000': ['make%2:41:00::'],\n",
       "  'd001.s015.t001': ['use%1:04:00::'],\n",
       "  'd001.s015.t002': ['retain%2:41:01::'],\n",
       "  'd001.s015.t003': ['include%2:42:00::'],\n",
       "  'd001.s016.t000': ['seek%2:40:00::'],\n",
       "  'd001.s016.t001': ['receive%2:40:00::'],\n",
       "  'd001.s016.t002': ['assistance%1:04:00::'],\n",
       "  'd001.s017.t000': ['become%2:42:01::'],\n",
       "  'd001.s017.t001': ['partner%1:18:00::'],\n",
       "  'd001.s018.t000': ['management%1:14:00::'],\n",
       "  'd001.s018.t001': ['use%2:34:01::'],\n",
       "  'd001.s018.t002': ['system%1:09:00::'],\n",
       "  'd001.s019.t000': ['receive%2:40:00::'],\n",
       "  'd001.s019.t001': ['equity%1:21:00::'],\n",
       "  'd001.s020.t000': ['find%2:39:05::'],\n",
       "  'd001.s020.t001': ['fate%1:11:00::'],\n",
       "  'd001.s020.t002': ['befall%2:30:01::'],\n",
       "  'd001.s020.t003': ['person%1:03:00::'],\n",
       "  'd001.s021.t000': ['fall_short%2:37:12::'],\n",
       "  'd001.s022.t000': ['show%2:32:00::'],\n",
       "  'd001.s022.t001': ['ingenuity%1:07:00::'],\n",
       "  'd001.s022.t002': ['find%2:39:02::'],\n",
       "  'd001.s023.t000': ['bribe%2:40:00::'],\n",
       "  'd001.s023.t001': ['shut_up%2:32:00::'],\n",
       "  'd001.s024.t000': ['want%2:37:00::'],\n",
       "  'd001.s024.t001': ['clothes%1:06:00::'],\n",
       "  'd001.s025.t000': ['wrestle%2:32:00::'],\n",
       "  'd001.s026.t000': ['change%2:30:04::'],\n",
       "  'd001.s026.t001': ['name%1:10:00::'],\n",
       "  'd001.s026.t002': ['become%2:42:01::'],\n",
       "  'd001.s026.t003': ['author%1:18:00::'],\n",
       "  'd001.s027.t000': ['enter%2:38:00::'],\n",
       "  'd001.s027.t001': ['get%2:30:00::'],\n",
       "  'd001.s027.t002': ['arrest%2:35:00::'],\n",
       "  'd001.s028.t000': ['absorb%2:31:03::'],\n",
       "  'd001.s028.t001': ['author%1:18:00::'],\n",
       "  'd001.s028.t002': ['gloss_over%2:41:00::'],\n",
       "  'd001.s028.t003': ['program%1:09:01::'],\n",
       "  'd001.s028.t004': ['scandal%1:11:00::'],\n",
       "  'd001.s028.t005': ['take_place%2:30:00::'],\n",
       "  'd001.s029.t000': ['come_around%2:31:00::'],\n",
       "  'd001.s029.t001': ['say%2:32:13::'],\n",
       "  'd001.s029.t002': ['court%1:14:00::'],\n",
       "  'd001.s029.t003': ['want%2:37:00::'],\n",
       "  'd001.s029.t004': ['end%2:30:01::'],\n",
       "  'd001.s029.t005': ['program%1:09:01::'],\n",
       "  'd001.s030.t000': ['leave%2:31:05::'],\n",
       "  'd001.s030.t001': ['gold%1:27:00::'],\n",
       "  'd001.s030.t002': ['express%2:32:01::'],\n",
       "  'd001.s030.t003': ['surprise%1:12:00::'],\n",
       "  'd001.s030.t004': ['walk%2:38:00::'],\n",
       "  'd001.s030.t005': ['scoop%2:35:01::'],\n",
       "  'd001.s031.t000': ['one%1:09:00::'],\n",
       "  'd001.s031.t001': ['have%2:42:00::'],\n",
       "  'd001.s031.t002': ['characteristic%1:09:00::'],\n",
       "  'd001.s032.t000': ['take_place%2:30:00::'],\n",
       "  'd001.s032.t001': ['program%1:09:01::'],\n",
       "  'd001.s032.t002': ['seem%2:39:00::'],\n",
       "  'd001.s033.t000': ['program%1:09:01::'],\n",
       "  'd001.s033.t001': ['eliminate%2:30:01::', 'eliminate%2:42:01::'],\n",
       "  'd001.s034.t000': ['provide%2:40:00::'],\n",
       "  'd001.s034.t001': ['clue%1:10:01::'],\n",
       "  'd001.s035.t000': ['group%1:03:00::'],\n",
       "  'd001.s035.t001': ['people%1:14:00::'],\n",
       "  'd001.s035.t002': ['describe%2:32:00::'],\n",
       "  'd001.s035.t003': ['belong%2:42:01::'],\n",
       "  'd001.s036.t000': ['know%2:31:01::'],\n",
       "  'd001.s036.t001': ['government%1:14:00::'],\n",
       "  'd001.s036.t002': ['redistribute%2:35:00::'],\n",
       "  'd001.s036.t003': ['wealth%1:21:02::'],\n",
       "  'd001.s036.t004': ['regulate%2:41:01::'],\n",
       "  'd001.s036.t005': ['commerce%1:04:00::'],\n",
       "  'd001.s036.t006': ['maintain%2:34:00::'],\n",
       "  'd001.s036.t007': ['establishment%1:14:00::'],\n",
       "  'd001.s036.t008': ['money%1:21:02::'],\n",
       "  'd001.s036.t009': ['make%2:40:01::'],\n",
       "  'd001.s036.t010': ['influence%2:41:00::'],\n",
       "  'd001.s036.t011': ['broker%2:40:00::'],\n",
       "  'd001.s036.t012': ['decision%1:09:00::'],\n",
       "  'd001.s037.t000': ['have%2:39:06::'],\n",
       "  'd001.s037.t001': ['wish%1:12:00::'],\n",
       "  'd001.s037.t002': ['see%2:39:02::'],\n",
       "  'd001.s037.t003': ['change%2:30:00::'],\n",
       "  'd001.s038.t000': ['exist%2:42:00::'],\n",
       "  'd001.s038.t001': ['line%1:10:01::'],\n",
       "  'd001.s038.t002': ['pocket%1:21:00::'],\n",
       "  'd001.s039.t000': ['issue%1:09:01::'],\n",
       "  'd001.s039.t001': ['raise%2:32:01::'],\n",
       "  'd002.s000.t000': ['reach%2:42:00::'],\n",
       "  'd002.s000.t001': ['lean%2:38:00::'],\n",
       "  'd002.s000.t002': ['ask%2:32:00::'],\n",
       "  'd002.s000.t003': ['want%2:37:00::'],\n",
       "  'd002.s000.t004': ['ride%2:38:00::'],\n",
       "  'd002.s001.t000': ['read%2:31:09::'],\n",
       "  'd002.s001.t001': ['take_up%2:42:00::'],\n",
       "  'd002.s002.t000': ['man%1:18:00::'],\n",
       "  'd002.s002.t001': ['represent%2:42:00::'],\n",
       "  'd002.s002.t002': ['attempt%1:04:00::'],\n",
       "  'd002.s002.t003': ['introduce%2:36:01::'],\n",
       "  'd002.s002.t004': ['bit%1:23:01::'],\n",
       "  'd002.s003.t000': ['embody%2:42:01::'],\n",
       "  'd002.s003.t001': ['state%1:03:00::'],\n",
       "  'd002.s003.t002': ['come_to%2:39:00::'],\n",
       "  'd002.s003.t003': ['try%2:41:00::'],\n",
       "  'd002.s003.t004': ['find%2:39:02::'],\n",
       "  'd002.s003.t005': ['machine%1:06:00::'],\n",
       "  'd002.s003.t006': ['have%2:40:05::'],\n",
       "  'd002.s004.t000': ['diner%1:18:00::'],\n",
       "  'd002.s004.t001': ['light%2:34:00::'],\n",
       "  'd002.s004.t002': ['scoff%2:32:00::'],\n",
       "  'd002.s004.t003': ['interrupt%2:32:00::'],\n",
       "  'd002.s004.t004': ['morning%1:28:00::'],\n",
       "  'd002.s005.t000': ['win%2:33:01::'],\n",
       "  'd002.s005.t001': ['response%1:10:00::'],\n",
       "  'd002.s006.t000': ['balloon%2:38:00::'],\n",
       "  'd002.s008.t000': ['seem%2:39:01::'],\n",
       "  'd002.s008.t001': ['follow%2:36:00::'],\n",
       "  'd002.s008.t002': ['lead%1:04:01::'],\n",
       "  'd002.s008.t003': ['take_to%2:41:01::'],\n",
       "  'd002.s009.t000': ['number%1:07:00::'],\n",
       "  'd002.s009.t001': ['pass%2:41:08::'],\n",
       "  'd002.s009.t002': ['test%1:10:00::'],\n",
       "  'd002.s009.t003': ['swell%2:30:02::'],\n",
       "  'd002.s009.t004': ['estimate%1:09:00::'],\n",
       "  'd002.s009.t005': ['run%2:42:07::'],\n",
       "  'd002.s010.t000': ['hold%2:36:00::'],\n",
       "  'd002.s010.t001': ['include%2:42:00::'],\n",
       "  'd002.s010.t002': ['attract%2:35:00::'],\n",
       "  'd002.s010.t003': ['balloon%1:06:00::'],\n",
       "  'd002.s010.t004': ['shape%2:30:00::', 'shape%2:36:00::'],\n",
       "  'd002.s010.t005': ['resemble%2:42:00::'],\n",
       "  'd002.s011.t000': ['balloon%1:06:00::'],\n",
       "  'd002.s011.t001': ['deny%2:40:01::'],\n",
       "  'd002.s011.t002': ['status%1:26:00::'],\n",
       "  'd002.s013.t000': ['hold%2:42:07::'],\n",
       "  'd002.s013.t001': ['attraction%1:07:00::'],\n",
       "  'd002.s014.t000': ['feel%2:39:01::', 'feel%2:37:00::'],\n",
       "  'd002.s014.t001': ['sign_up%2:33:00::'],\n",
       "  'd002.s015.t000': ['thing%1:10:00::'],\n",
       "  'd002.s015.t001': ['tell%2:32:00::'],\n",
       "  'd002.s015.t002': ['require%2:42:00::'],\n",
       "  'd002.s015.t003': ['zip%1:07:00::'],\n",
       "  'd002.s016.t000': ['look%2:39:00::'],\n",
       "  'd002.s017.t000': ['tell%2:32:00::'],\n",
       "  'd002.s017.t001': ['hate%2:37:00::'],\n",
       "  'd002.s017.t002': ['balloon%2:38:00::'],\n",
       "  'd002.s018.t000': ['say%2:32:13::'],\n",
       "  'd002.s018.t001': ['look%2:39:00::'],\n",
       "  'd002.s019.t000': ['ascend%2:38:02::'],\n",
       "  'd002.s020.t000': ['tell%2:32:00::'],\n",
       "  'd002.s020.t001': ['go%2:30:04::'],\n",
       "  'd002.s020.t002': ['want%2:37:00::'],\n",
       "  'd002.s020.t003': ['get%2:30:00::'],\n",
       "  'd002.s021.t000': ['refer%2:32:01::'],\n",
       "  'd002.s022.t000': ['talk%2:32:01::'],\n",
       "  'd002.s024.t000': ['pilot%1:18:00::'],\n",
       "  'd002.s024.t001': ['speak%2:32:02::'],\n",
       "  'd002.s025.t000': ['refer%2:31:00::'],\n",
       "  'd002.s025.t001': ['begin%2:42:04::'],\n",
       "  'd002.s025.t002': ['end%2:42:00::'],\n",
       "  'd002.s026.t000': ['flight%1:04:00::'],\n",
       "  'd002.s026.t001': ['occur%2:30:00::'],\n",
       "  'd002.s027.t000': ['come%2:42:05::'],\n",
       "  'd002.s027.t001': ['lot%1:23:00::'],\n",
       "  'd002.s027.t002': ['watch%2:39:00::'],\n",
       "  'd002.s027.t003': ['balloon%1:06:00::'],\n",
       "  'd002.s027.t004': ['inflate%2:30:02::'],\n",
       "  'd002.s027.t005': ['stand%2:35:00::'],\n",
       "  'd002.s027.t006': ['decide%2:31:00::'],\n",
       "  'd002.s027.t007': ['fly%2:38:05::'],\n",
       "  'd002.s027.t008': ['basket%1:06:00::'],\n",
       "  'd002.s027.t009': ['hold%2:42:14::'],\n",
       "  'd002.s028.t000': ['follow%2:31:00::'],\n",
       "  'd002.s028.t001': ['progress%1:11:00::'],\n",
       "  'd002.s028.t002': ['listen%2:39:00::'],\n",
       "  'd002.s028.t003': ['driver%1:18:00::'],\n",
       "  'd002.s028.t004': ['holler%2:32:06::'],\n",
       "  'd002.s029.t000': ['come%2:42:05::'],\n",
       "  'd002.s029.t001': ['minute%1:28:00::'],\n",
       "  'd002.s029.t002': ['drift%2:38:02::'],\n",
       "  'd002.s029.t003': ['watch%2:39:00::'],\n",
       "  'd002.s029.t004': ['rise%2:38:00::'],\n",
       "  'd002.s029.t005': ['cow%1:05:01::'],\n",
       "  'd002.s029.t006': ['amble%2:38:00::'],\n",
       "  'd002.s030.t000': ['feel%2:31:00::'],\n",
       "  'd002.s030.t001': ['keep%2:42:07::'],\n",
       "  'd002.s030.t002': ['point_out%2:32:01::'],\n",
       "  'd002.s031.t000': ['come%2:38:00::'],\n",
       "  'd002.s031.t001': ['put%2:35:00::'],\n",
       "  'd002.s031.t002': ['hand%1:08:00::'],\n",
       "  'd002.s031.t003': ['squint%2:29:02::'],\n",
       "  'd002.s033.t000': ['come%2:38:00::'],\n",
       "  'd002.s034.t000': ['see%2:31:01::'],\n",
       "  'd002.s034.t001': ['steer%2:38:00::'],\n",
       "  'd002.s036.t000': ['go%2:38:00::'],\n",
       "  'd002.s036.t001': ['heat%2:30:01::'],\n",
       "  'd002.s036.t002': ['air%1:27:00::'],\n",
       "  'd002.s036.t003': ['burner%1:06:00::'],\n",
       "  'd002.s036.t004': ['make%2:30:00::'],\n",
       "  'd002.s036.t005': ['top%1:15:01::'],\n",
       "  'd002.s036.t006': ['feel%2:42:00::'],\n",
       "  'd002.s036.t007': ['ride%2:42:04::'],\n",
       "  'd002.s036.t008': ['current%1:11:00::'],\n",
       "  'd002.s037.t000': ['make%2:30:00::'],\n",
       "  'd002.s037.t001': ['car%1:06:00::'],\n",
       "  'd002.s038.t000': ['go%2:38:00::'],\n",
       "  'd002.s038.t001': ['average%2:41:00::'],\n",
       "  'd002.s038.t002': ['hour%1:28:00::'],\n",
       "  'd002.s039.t000': ['balloon%1:06:00::'],\n",
       "  'd002.s039.t001': ['cruise%2:38:02::'],\n",
       "  'd002.s040.t000': ['ascend%2:38:02::'],\n",
       "  'd002.s040.t001': ['descend%2:38:00::'],\n",
       "  'd002.s041.t000': ['do%2:36:01::'],\n",
       "  'd002.s041.t001': ['hiss%2:32:01::'],\n",
       "  'd002.s041.t002': ['companion%1:18:02::'],\n",
       "  'd002.s042.t000': ['yell%2:32:00::'],\n",
       "  'd002.s042.t001': ['pilot%1:18:00::'],\n",
       "  'd002.s042.t002': ['basket%1:06:00::'],\n",
       "  'd002.s042.t003': ['plunge%2:38:00::'],\n",
       "  'd002.s043.t000': ['yell%2:32:00::'],\n",
       "  'd002.s043.t001': ['leap%2:38:00::'],\n",
       "  'd002.s043.t002': ['wear%2:29:00::'],\n",
       "  'd002.s043.t003': ['loafer%1:06:00::'],\n",
       "  'd002.s044.t000': ['pilot%1:18:00::'],\n",
       "  'd002.s044.t001': ['laugh%2:29:00::'],\n",
       "  'd002.s044.t002': ['burner%1:06:00::'],\n",
       "  'd002.s044.t003': ['lift%2:38:00::'],\n",
       "  'd002.s045.t000': ['scuttle%2:38:00::'],\n",
       "  'd002.s045.t001': ['plunge%2:35:00::'],\n",
       "  'd002.s046.t000': ['come%2:30:03::'],\n",
       "  'd002.s046.t001': ['rest%2:35:00::'],\n",
       "  'd002.s046.t002': ['have%2:39:06::'],\n",
       "  'd002.s046.t003': ['pleasure%1:09:00::'],\n",
       "  'd002.s046.t004': ['scramble%2:38:01::'],\n",
       "  'd002.s046.t005': ['half%1:23:00::'],\n",
       "  'd002.s046.t006': ['scramble%2:38:01::'],\n",
       "  'd002.s047.t000': ['look%2:39:00::'],\n",
       "  'd002.s049.t000': ['drive%2:38:00::'],\n",
       "  'd002.s049.t001': ['get%2:30:00::'],\n",
       "  'd002.s049.t002': ['get_stuck%2:38:00::'],\n",
       "  'd002.s049.t003': ['enlist%2:40:00::'],\n",
       "  'd002.s049.t004': ['aid%1:04:00::'],\n",
       "  'd002.s049.t005': ['farmer%1:18:00::'],\n",
       "  'd002.s049.t006': ['get_out%2:35:00::'],\n",
       "  'd002.s049.t007': ['hitch%1:06:01::'],\n",
       "  'd002.s049.t008': ['pull_out%2:35:00::'],\n",
       "  'd002.s050.t000': ['rendezvous%2:41:00::'],\n",
       "  'd002.s050.t001': ['balloon%1:06:00::'],\n",
       "  'd002.s050.t002': ['come%2:30:03::'],\n",
       "  'd002.s050.t003': ['rest%2:35:00::'],\n",
       "  'd002.s050.t004': ['watch%2:39:00::'],\n",
       "  'd002.s050.t005': ['disassemble%2:36:00::'],\n",
       "  'd002.s050.t006': ['craft%1:06:00::'],\n",
       "  'd002.s050.t007': ['activity%1:04:00::'],\n",
       "  'd002.s050.t008': ['include%2:42:00::'],\n",
       "  'd002.s050.t009': ['routine%1:04:00::'],\n",
       "  'd002.s050.t010': ['yank%2:35:00::'],\n",
       "  'd002.s050.t011': ['punch%2:35:00::'],\n",
       "  'd002.s050.t012': ['air%1:27:00::'],\n",
       "  'd002.s050.t013': ['roll_up%2:35:00::'],\n",
       "  'd002.s050.t014': ['cram%2:35:10::'],\n",
       "  'd002.s050.t015': ['basket%1:06:00::'],\n",
       "  'd002.s051.t000': ['exercise%1:04:00::'],\n",
       "  'd002.s051.t001': ['have%2:39:06::'],\n",
       "  'd002.s051.t002': ['follow%2:42:01::'],\n",
       "  'd002.s051.t003': ['drive%2:38:00::'],\n",
       "  'd002.s052.t000': ['mean%2:42:00::'],\n",
       "  'd002.s052.t001': ['return%2:38:00::'],\n",
       "  'd002.s052.t002': ['watch%2:39:00::'],\n",
       "  'd002.s052.t003': ['duffer%1:18:00::'],\n",
       "  'd002.s052.t004': ['maul%2:35:00::'],\n",
       "  'd002.s052.t005': ['tee%1:15:00::'],\n",
       "  'd002.s052.t006': ['sit%2:35:00::'],\n",
       "  'd002.s052.t007': ['ego%1:12:01::'],\n",
       "  'd002.s054.t000': ['figure%2:31:01::'],\n",
       "  'd002.s055.t000': ['clamber%2:38:00::'],\n",
       "  'd002.s056.t000': ['leave%2:31:05::'],\n",
       "  'd002.s056.t001': ['ride%2:38:00::'],\n",
       "  'd002.s057.t000': ['streak%2:38:00::'],\n",
       "  'd002.s057.t001': ['resist%2:33:00::'],\n",
       "  'd002.s057.t002': ['rear%2:38:00::'],\n",
       "  'd002.s057.t003': ['salute%2:32:01::']},\n",
       " 'data': [('', 'd000', <DOM Element: text at 0x7fbd74c4ecb0>),\n",
       "  ('', 'd001', <DOM Element: text at 0x7fbd74e34550>),\n",
       "  ('', 'd002', <DOM Element: text at 0x7fbd6db941f0>)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which sense of the word „peculiar” is expressed in the following context:\n",
    "\n",
    "# „The art of change-ringing is peculiar to the English, and, like most English peculiarities, unintelligible to the rest of the world. Dorothy L. Sayers, `` The Nine Tailors`` ASLACTON, England-- Of all scenes that evoke rural England, this is one of the loveliest: An ancient stone church stands amid the fields, the sound of bells cascading from its tower, calling the faithful to evensong. The parishioners of St. Michael and All Angels stop to chat at the church door, as members here always have. ”. The senses are as follows:\n",
    "\n",
    "# {\n",
    "# „peculiar%5:00:00:characteristic:00”: „peculiar: characteristic of one only; distinctive or special”,\n",
    "# „peculiar%5:00:00:specific:00”: „peculiar: unique or specific to a person or thing or category”,\n",
    "# „peculiar%5:00:00:strange:00”: „peculiar: beyond or deviating from the usual or expected”,\n",
    "# „peculiar%5:00:00:unusual:00”: „peculiar: markedly different from the usual”\n",
    "# }\n",
    "\n",
    "# Return the key of the correct sense.\n",
    "\n",
    "with open('wsd-prompts-s07.tsv', 'w') as ofile:\n",
    "\n",
    "    for ((lemma, pos, instance), context) in contexts:\n",
    "        if instance not in gold:\n",
    "            print(instance)\n",
    "            continue\n",
    "\n",
    "        glosses = str({\n",
    "            key: gloss for _, (key, gloss) in enumerate(\n",
    "                inventory.lemma_glosses(lemma, pos, ret_key=True)\n",
    "            )\n",
    "        })\n",
    "\n",
    "        context = ' '.join([\n",
    "            parse_sentence(sentence) for sentence in context\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"Which meaning of the word „{lemma}” is expressed in the following context: \"{context}\" The meanings are as follows: {glosses}. Return only the key of the most relevant meaning.\"\"\"\n",
    "        ofile.write(f\"{instance}\\t{prompt}\\t{gold[instance]}\\t\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d787e4610706c7cbee5b36101a3dcd5e1b2a4eec4a05bf333cd65971af93240"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
